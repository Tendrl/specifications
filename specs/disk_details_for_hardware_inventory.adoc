// vim: tw=79

= Specification for adding disk details in node hardware inventory

Add disk details also as a part of node hardware inventory

== Problem description

Hardware inventory details are used to show exact status of the particular
node. Currently disk details are missing in node hardware inventory. Add all
possible disk details in node hardware inventory and store it in etcd.

This specification focuses on gathering all the information about disks
attached to a system, including their partitioning information and block
devices. This spec does not address either LVM or RAID devices. Separate specs
need to be filed for both.

== Use Cases

Tendrl needs to be able to track locally attached physical storage, such as
hard drives, solid state drives etc.

== Proposed change

Gather all the possible details about the locally attached disks and the
corresponding device hierarchy and store it in etcd for consumption by clients
via the API.

The information to be gathered from the system includes:

* Disk hardware details.
* Block details of the block devices the system identifies the disks as.
* The /dev/disk hierarchy which indexes the block devices based on various
  types of identifiers.

It is also necessary to identify disks (and the corresponding block devices) as
used. Any disk that does not contain a partition table is considered to be
unused.

== Data model impact

The data model for disk inventory is:

```
attributes of tendrl.objects.Disk class

	disk_id (manufacturer-id+vendor-id+device-serial-number)
	unique_id (hwinfo id)
    	disk_type
       	model
    	vendor
       	serial_no
       	device_name
      	sysfs_id
     	sysfs_busid
     	sysfs_device_link
      	driver_modules
    	driver
    	device_files
      	device_number
      	device
      	drive_status
      	rmversion
       	bios_id
      	geo_bios_edd
      	geo_bios_legacy
     	geo_logical
     	disk_kernel_name
      	major_to_minor_no
     	fstype
   	label
    	fsuuid
     	read_ahead
     	read_only
    	removable_device
      	size
      	state
 	owner
   	group
   	mode
    	alignement
     	min_io_size
   	optimal_io_size
   	phy_sector_size
    	log_sector_size
    	ssd
       	scheduler_name
    	req_queue_size
    	discard_align_offset
      	discard_granularity
     	discard_max_bytes
      	discard_zeroes_data
	discard_max_bytes
     	discard_zeros_data
	partition (json)
```

Partiton json structure in disk object is:
```
	unique_id
    	disk_id
    	type
    	device_name
	parent_name
       	sysfs_id
    	device_files
   	disk_kernel_name
      	major_to_minor_no
      	fstype
      	mount_point
        label
        fsuuid
      	read_ahead
      	read_only
       	removable_device
      	size
    	state
      	owner
    	group
        mode
       	alignement
       	min_io_size
       	optimal_io_size
	log_sector_size
        scheduler_name
        req_queue_size
	discard_granularity
        discard_max_bytes
        discard_zeros_data
```

== `nodes/<node_id>/Disks`

This directory contains all the hardware information about the disks and the
various devices from the `/dev/disk` hierarchy on the system.

* In this location we store all the physical disks available on the node with 
  a unique key, one object per disk.
* The disk object contains:
** all the hardware information about the disk
** parition table and hardware information about all the paritions on the disk
** a pointer to the block device the disk is identified as
* The id for the disk object is in the following format:
  `<vendor>_<model>_<serial_number>`.
* The `/dev/disk` hierarchy is stored as is as the `Disks/raw_references`
  object. The entire directory structure is read from the system and is stored
  as-is. This allows easier sync by validating the checksum of the value of
  this object against the directory structure's data from the system.
* The `Disks/references` object is generated as the json representation of the
  `raw_references` object each time the said object is updated as part of the
  sync.

```
     list: nodes/$Node_context.node_id/Disks/`<vendor>_<model>_<serial_number>`
```

=== `nodes/<node_id>/block_devices`

This is the location to store the details about block-devices available on the node.
This section will have following sub sections:

* Block device details go to `nodes/<node_id>/block_devices/all`.	
* Objects in this directory are populated based on the output of `lsblk`. More
  details below.
* Each block device object's key is the device name, such as `vda`, `sda`,
  `nvme0` etc.
* All the partition information about the block device is contained in the
  object representing the disk device itself. No separate device hierarchy is
  created for individual partitions.
* Each block device object must contain the id of the disk it represents, as
   the value of the attribute `disk_id`.
* If a disk has partitions, an empty object with it’s id is created under Disks/used.
* If a disk has no partition table, an empty object with it’s id is created under Disks/free.
  the key for each block-device would be its name where "/" is replaced by "_" For example a 
  device /dev/vda would be listed as "_dev_vda".
* Here each block device will have links to the underlying disks which are located at: 
  /nodes/<node-id>/disks/<disk-unique-id>

```
     list: nodes/$Node_context.node_id/block_devices/all
     list: nodes/$Node_context.node_id/block_devices/used
     list: nodes/$Node_context.node_id/block_devices/free
```

NOTE: 1. During inventory sync we have to make sure that if at all any previously
         free device is used now, we have to properly update this by moving the
         free block device from /free to /used.
      2. Also the links between block devices and disks have to be kept up to date,
         so that even if block-device name changes after reboot. it should properly
         be reflected in the disk inventory.

== Impacted modules

== Tendrl API impact:

Api has to note that the disk inventory model has changed and this will need changes
in api to consume disk details as per new model

=== Tendrl/common impact

None

=== Tendrl/node_agent impact

* Create a new class for disk.
* Create a new function in node sync to collect disk details.
* Create a new object for disk in definition file.
* Collect all disk details from node sync and store it in etcd using disk class object.
* Store Block device details also in etcd.
* Expected disk details output format form  hardware inventory list is:
```
Example raw_json

{
  "Disks":{
	"disk_id1":{
	    disk_id: "" (not decided)
            unique_id: "3OOL.qPX1W_dGFo7"
            disk_type: "disk"
            model: "SAMSUNG MZ7TE512"
            vendor: "SAMSUNG"
            serial_no: "S1GJNSAG400778"
            device_name: "/dev/sda"
            sysfs_id: "/class/block/sda"
            sysfs_busid: "0:0:0:0"
            sysfs_device_link: "/devices/pci0000:00/0000:00:1f.2/ata1/host0/target0:0:0/0:0:0:0"
            driver_modules: "ahci"
            driver: ["ahci", "sd"]
            device_files: "/dev/sda, /dev/disk/by-id/ata-SAMSUNG_MZ7TE512HMHP-000L1_S1GJNSAG400778, /dev/                          disk/by-id/wwn-0x4d30445853885002"
            device_number: "block 8:0-8:15"
            device: "/dev/sda"
            drive_status: "no medium"
            rmversion: "6L0Q"
            bios_id: "0x80"
            geo_bios_edd: "CHS 992277/16/63"
            geo_bios_legacy: "CHS 1023/255/63"
            geo_logical: "CHS 62260/255/63"
            disk_kernel_name: "/dev/sda"
            major_to_minor_no: "8:0"
            fstype: "LVM2_member"
            mount_point: ""
            label: ""
            fsuuid: ""
            read_ahead: "128"
            read_only: "0"
            removable_device: "0"
            size: "10737418240"
            state: "running"
            owner: "root"
            group: "disk"
            mode: "brw-rw----"
            alignement: "0"
            min_io_size: "512"
            optimal_io_size: "0"
            phy_sector_size: "512"
            log_sector_size: "512"
            ssd: "True"
            scheduler_name: "cfq"
            req_queue_size: "128"
            discard_align_offset: "0"
            discard_granularity: "0"
	    discard_max_bytes: "0"
	    discard_zeros_data: "0"
	    partition:{
            		unique_id: "2pkM.SE1wIdpsiiC"
                        parent_name: "3OOL.iLjwFstLQvC"
            		disk_type: "partition"
            		device_name: "/dev/sda1"
            		sysfs_id: "/class/block/sda/sda1"
            		device_files: "/dev/sda1, /dev/disk/by-id/ata-SAMSUNG_MZ7TE512HMHP-000L1_S1GJNSAG                                      400778-part1, /dev/disk/by-id/wwn-0x4d30445853885002-part1, /dev/di                                      sk/by-uuid/fff-c5ec-4674-894a-d9ae57b8243c"
            		disk_kernel_name: "/dev/sda1"
            		major_to_minor_no: "8:1"
            		fstype: "ext4"
            		mount_point: "/boot"
            		label: ""
            		fsuuid: "dda9f15f-c5ec-4674-894a-d9ae57b8243c"
            		read_ahead: "128"
            		read_only: "0"
            		removable_device: "0"
            		size: "10737418240"
            		state: ""
            		owner: "root"
            		group: "disk"
            		mode: "brw-rw----"
            		alignement: "0"
            		min_io_size: "512"
            		optimal_io_size: "0"
            		phy_sector_size: "512"
            		log_sector_size: "512"
            		ssd: ""
            		scheduler_name: "cfq"
            		req_queue_size: "128"
            		discard_align_offset: "0"
            		discard_granularity: "0"
            		discard_max_bytes: "0"
            		discard_zeros_data: "0"
		}

	}
	"disk_id2": {
		//same as disk_id1 structure
	}
   }
   "all_block_device":{
     	"/dev/vda" : "disk/manufacturer-id+vendor-id+device-serial-number",
	"/dev/vda1": "disk/manufacturer-id+vendor-id+device-serial-number/partition/dev/vda1"
	"/dev/vdb" : "disk/manufacturer-id+vendor-id+device-serial-number"
   }
   "used_block_device":{
	"/dev/vda": "disk/manufacturer-id+vendor-id+device-serial-number",
        "/dev/vda1": "disk/manufacturer-id+vendor-id+device-serial-number/partition/dev/vda1"
   }
   "free_block_device"{
	"/dev/vdb": "disk/manufacturer-id+vendor-id+device-serial-number"
  }
}
```

=== Tendrl/gluster_integration impact

None

=== Tendrl/ceph_integration impact

None


== Security impact

None

== Notifications/Monitoring impact

Monitoring module has to note that the disk inventory model has changed and this
might need changes to consume disk details as per new model


== Other end user impact

None

== Performance Impact

None

== Other deployer impact

None

== Developer impact

None

== Implementation

* `hwinfo` and `lsblk` to find the disk details.
* `lsblk` is used for gathering block device information.
* All disk details are stored under /node/{node_id}/disks/{disk_id} in etcd in hierarchical order.
* Object is created from raw_json in node sync, It contains disk, partitions informations in hierarchical order.
* raw_json is stored in etcd using disk class object.


== Alternatives

hdparm is also giving some disk details like serial number and firmware but it
works only for ATA disks types. For SCSI disk we have to use sdparm.


== Assignee(s)

Primary assignee: Gowtham Shanmugasundaram

Other contributor(s): TODO

== Work Items

* git-hub issue: https://github.com/Tendrl/node_agent/issues/78

== Dependencies

Add hwinfo to retrieve disk details (pip package is not required for these two,
It is used for system command). hwinfo is not available for rhel and epel, we
have to build this.

== Testing

* Sanity check for flow.
* Check all disk details are persisted successfully.

== Documentation impact

None

== References

None
